service: aws-python
provider:
  name: aws
  runtime: python2.7
  region: us-east-2
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:*
        - dynamodb:*
      Resource: "*"

functions:
  test-read-s3:
    handler: handler.csv_handler
    events:
      - s3: # in this case, instead of http call, s3 will trigger the event to invoke our lambda function
          bucket: input-csv
          event: s3:ObjectCreated:* # the hello function will be invoked automatically upon file uploaded
          rules:
            - suffix: .csv

  test-stream:
    handler: handler.stream_handler
    events:
      - stream:
          type: dynamodb
          batchSize: 20
          startingPosition: TRIM_HORIZON
          arn:
            Fn::GetAtt:
              - test
              - StreamArn

resources:
  Resources:
    test:
      Type: "AWS::DynamoDB::Table"
      DeletionPolicy: Delete
      Properties:
        AttributeDefinitions:
          -
            AttributeName: tracking_no
            AttributeType: S
        KeySchema:
          -
            AttributeName: tracking_no
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1
        StreamSpecification:
          StreamViewType: NEW_IMAGE
        TableName: "raw_orders"

    mapped:
      Type: "AWS::DynamoDB::Table"
      DeletionPolicy: Delete
      Properties:
        AttributeDefinitions:
          -
            AttributeName: item_id
            AttributeType: N
        KeySchema:
          -
            AttributeName: item_id
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1
        TableName: "mapped_orders"